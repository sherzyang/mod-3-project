{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines():\n",
    "    with open('kickstarter-projects/ks-projects-201612.csv', 'rb') as f:\n",
    "        for line in f: \n",
    "            yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weird_lines():\n",
    "    for i, line in enumerate(get_lines()):\n",
    "        for char in line: \n",
    "            if char > 127:\n",
    "                yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_lines = get_weird_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(weird_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = next(weird_lines)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = pd.read_csv('kickstarter-projects/ks-projects-201612.csv', encoding ='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = df_2016.drop(['Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15',\n",
    "       'Unnamed: 16'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = df_2016.rename(columns={'ID ': 'ID', 'name ': 'name', 'category ': 'category', \n",
    "                        'main_category ': 'main_category', 'currency ': 'currency',\n",
    "                        'deadline ': 'deadline', 'goal ': 'goal', 'launched ': 'launched',\n",
    "                        'pledged ': 'pledged', 'state ': 'state', 'backers ': 'backers',\n",
    "                        'country ': 'country', 'usd pledged ':'usd_pledged'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016_all = df_2016.loc[(df_2016['state'] == 'failed') | \n",
    "                      (df_2016['state'] == 'canceled') | \n",
    "                      (df_2016['state'] == 'successful') | \n",
    "                      (df_2016['state'] == 'live') | \n",
    "                      (df_2016['state'] == 'suspended') | \n",
    "                      (df_2016['state'] == 'undefined')]\n",
    "\n",
    "#The 2016 data set is very unreliable across the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to use our 2018 data set instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from IPython.display import Image  \n",
    "from sklearn import tree\n",
    "#import pydotplus\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = pd.read_csv('kickstarter-projects/ks-projects-201801.csv', encoding ='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>goal</th>\n",
       "      <th>launched</th>\n",
       "      <th>pledged</th>\n",
       "      <th>state</th>\n",
       "      <th>backers</th>\n",
       "      <th>country</th>\n",
       "      <th>usd pledged</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <th>usd_goal_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002330</td>\n",
       "      <td>The Songs of Adelaide &amp; Abullah</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2015-10-09</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2015-08-11 12:12:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1533.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000003930</td>\n",
       "      <td>Greeting From Earth: ZGAC Arts Capsule For ET</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>2017-09-02 04:43:57</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>15</td>\n",
       "      <td>US</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>30000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000004038</td>\n",
       "      <td>Where is Hank?</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>2013-01-12 00:20:50</td>\n",
       "      <td>220.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>45000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000007540</td>\n",
       "      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>2012-04-16</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2012-03-17 03:24:11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000011046</td>\n",
       "      <td>Community Film Project: The Art of Neighborhoo...</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2015-08-29</td>\n",
       "      <td>19500.0</td>\n",
       "      <td>2015-07-04 08:35:03</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>canceled</td>\n",
       "      <td>14</td>\n",
       "      <td>US</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>19500.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               name  \\\n",
       "0  1000002330                    The Songs of Adelaide & Abullah   \n",
       "1  1000003930      Greeting From Earth: ZGAC Arts Capsule For ET   \n",
       "2  1000004038                                     Where is Hank?   \n",
       "3  1000007540  ToshiCapital Rekordz Needs Help to Complete Album   \n",
       "4  1000011046  Community Film Project: The Art of Neighborhoo...   \n",
       "\n",
       "         category main_category currency    deadline     goal  \\\n",
       "0          Poetry    Publishing      GBP  2015-10-09   1000.0   \n",
       "1  Narrative Film  Film & Video      USD  2017-11-01  30000.0   \n",
       "2  Narrative Film  Film & Video      USD  2013-02-26  45000.0   \n",
       "3           Music         Music      USD  2012-04-16   5000.0   \n",
       "4    Film & Video  Film & Video      USD  2015-08-29  19500.0   \n",
       "\n",
       "              launched  pledged     state  backers country  usd pledged  \\\n",
       "0  2015-08-11 12:12:28      0.0    failed        0      GB          0.0   \n",
       "1  2017-09-02 04:43:57   2421.0    failed       15      US        100.0   \n",
       "2  2013-01-12 00:20:50    220.0    failed        3      US        220.0   \n",
       "3  2012-03-17 03:24:11      1.0    failed        1      US          1.0   \n",
       "4  2015-07-04 08:35:03   1283.0  canceled       14      US       1283.0   \n",
       "\n",
       "   usd_pledged_real  usd_goal_real  \n",
       "0               0.0        1533.95  \n",
       "1            2421.0       30000.00  \n",
       "2             220.0       45000.00  \n",
       "3               1.0        5000.00  \n",
       "4            1283.0       19500.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 378661 entries, 0 to 378660\n",
      "Data columns (total 15 columns):\n",
      "ID                  378661 non-null int64\n",
      "name                378657 non-null object\n",
      "category            378661 non-null object\n",
      "main_category       378661 non-null object\n",
      "currency            378661 non-null object\n",
      "deadline            378661 non-null object\n",
      "goal                378661 non-null float64\n",
      "launched            378661 non-null object\n",
      "pledged             378661 non-null float64\n",
      "state               378661 non-null object\n",
      "backers             378661 non-null int64\n",
      "country             378661 non-null object\n",
      "usd pledged         374864 non-null float64\n",
      "usd_pledged_real    378661 non-null float64\n",
      "usd_goal_real       378661 non-null float64\n",
      "dtypes: float64(5), int64(2), object(8)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detects the live in state and drops them \n",
    "df_2018 = df_2018.loc[df_2018['state']!='live']\n",
    "\n",
    "#Detects the undefined in state and drops them \n",
    "df_2018 = df_2018.loc[df_2018['state']!='undefined']\n",
    "\n",
    "#Detects the undefined in state and drops them \n",
    "df_2018 = df_2018.loc[df_2018['state']!='canceled']\n",
    "\n",
    "#Detects the undefined in state and drops them \n",
    "df_2018 = df_2018.loc[df_2018['state']!='suspended']\n",
    "\n",
    "#Detects the undefined in usd pledged and drops them \n",
    "df_2018 = df_2018.loc[~df_2018['usd pledged'].isna(), :]\n",
    "\n",
    "#Detects the undefined in usd pledged and drops them \n",
    "df_2018 = df_2018.loc[~df_2018['name'].isna(), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A look at successes and failures by main category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018['main_category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_df = df_2018.loc[df_2018['state'] =='successful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_df = df_2018.loc[df_2018['state'] =='failed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_list = successful_df['main_category'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_list = failed_df['main_category'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "list1=successful_list\n",
    "counts_s = Counter(list1)\n",
    "print(counts_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2=failed_list\n",
    "counts_f = Counter(list2)\n",
    "print(counts_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data to plot\n",
    "n_groups = 15\n",
    "successful = counts_s.values()\n",
    "failed = counts_f.values()\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = plt.bar(index, successful, bar_width,\n",
    "alpha=opacity,\n",
    "color='black',\n",
    "label='successful')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, failed, bar_width,\n",
    "alpha=opacity,\n",
    "color='grey',\n",
    "label='failed')\n",
    "\n",
    "plt.xlabel('Main Category')\n",
    "plt.ylabel('Projects on Kickstarter in 2018')\n",
    "plt.title('Successes & Failures By Category')\n",
    "plt.xticks(index + bar_width, counts_s.keys())\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successes_tuples = [(key, value) for (key, value) in sorted(counts_s.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_tuples = [(key, value) for (key, value) in sorted(counts_f.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = []\n",
    "for i in range(15):\n",
    "    numerator = list(successes_tuples[i])[1] - list(failed_tuples[i])[1]\n",
    "    denominator = list(successes_tuples[i])[1] + list(failed_tuples[i])[1]\n",
    "    temp = numerator/denominator\n",
    "    difference.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = list(dict(successes_tuples).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = category_names\n",
    "values = difference\n",
    "dictionary = dict(zip(keys, values))\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "sns.set(style=\"white\", context=\"talk\")\n",
    "f, ax1 = plt.subplots(figsize=(15,5))\n",
    "\n",
    "# Generate some sequential data\n",
    "x = category_names\n",
    "y1 = difference\n",
    "g = sns.barplot(x=x, y=y1, palette=\"GnBu_d\")\n",
    "ax1.axhline(0, color=\"k\", clip_on=False)\n",
    "ax1.set_ylabel(\"percent\")\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=30)\n",
    "\n",
    "label = [\"{:.2%}\".format(x) for x in difference]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's start to engineer our features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_2018.drop(\"state\", axis=1),\n",
    "                                                    df_2018[\"state\"],\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=2019)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(failed        148193\n",
       " successful    100403\n",
       " Name: state, dtype: int64, failed        49418\n",
       " successful    33448\n",
       " Name: state, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(), y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248596, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip freeze | grep sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train['country'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto', drop='first',\n",
       "              dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "              n_values=None, sparse=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(drop='first', categories=\"auto\")\n",
    "encoder.fit(X_train[[\"main_category\", \"country\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Art', 'Comics', 'Crafts', 'Dance', 'Design', 'Fashion',\n",
       "        'Film & Video', 'Food', 'Games', 'Journalism', 'Music',\n",
       "        'Photography', 'Publishing', 'Technology', 'Theater'], dtype=object),\n",
       " array(['AT', 'AU', 'BE', 'CA', 'CH', 'DE', 'DK', 'ES', 'FR', 'GB', 'HK',\n",
       "        'IE', 'IT', 'JP', 'LU', 'MX', 'NL', 'NO', 'NZ', 'SE', 'SG', 'US'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder.get_feature_names(['main_category', 'country']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<248596x35 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 477651 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.transform(X_train[[\"main_category\", \"country\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['main_category_Comics', 'main_category_Crafts',\n",
       "       'main_category_Dance', 'main_category_Design',\n",
       "       'main_category_Fashion', 'main_category_Film & Video',\n",
       "       'main_category_Food', 'main_category_Games',\n",
       "       'main_category_Journalism', 'main_category_Music',\n",
       "       'main_category_Photography', 'main_category_Publishing',\n",
       "       'main_category_Technology', 'main_category_Theater', 'country_AU',\n",
       "       'country_BE', 'country_CA', 'country_CH', 'country_DE',\n",
       "       'country_DK', 'country_ES', 'country_FR', 'country_GB',\n",
       "       'country_HK', 'country_IE', 'country_IT', 'country_JP',\n",
       "       'country_LU', 'country_MX', 'country_NL', 'country_NO',\n",
       "       'country_NZ', 'country_SE', 'country_SG', 'country_US'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.get_feature_names([\"main_category\", \"country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = pd.DataFrame(encoder.transform(X_train[[\"main_category\", \"country\"]]).toarray(),\n",
    "                  columns=encoder.get_feature_names([\"main_category\", \"country\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>goal</th>\n",
       "      <th>launched</th>\n",
       "      <th>pledged</th>\n",
       "      <th>backers</th>\n",
       "      <th>country</th>\n",
       "      <th>usd pledged</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <th>usd_goal_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1426698687</td>\n",
       "      <td>RAPPY: The 3D printer with position feedback c...</td>\n",
       "      <td>3D Printing</td>\n",
       "      <td>Technology</td>\n",
       "      <td>USD</td>\n",
       "      <td>2014-02-16</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2014-01-16 04:48:30</td>\n",
       "      <td>21543.00</td>\n",
       "      <td>49</td>\n",
       "      <td>US</td>\n",
       "      <td>21543.00</td>\n",
       "      <td>21543.00</td>\n",
       "      <td>100000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1633937505</td>\n",
       "      <td>Unborn in America - A New Cabaret Opera</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Theater</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2014-12-03</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2014-11-06 23:41:21</td>\n",
       "      <td>2600.00</td>\n",
       "      <td>74</td>\n",
       "      <td>GB</td>\n",
       "      <td>4162.44</td>\n",
       "      <td>4078.30</td>\n",
       "      <td>3921.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>815178419</td>\n",
       "      <td>The Chronicles of Count Carlos: Son of Dracula</td>\n",
       "      <td>Comic Books</td>\n",
       "      <td>Comics</td>\n",
       "      <td>USD</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>2016-07-03 19:39:13</td>\n",
       "      <td>12813.01</td>\n",
       "      <td>193</td>\n",
       "      <td>US</td>\n",
       "      <td>629.00</td>\n",
       "      <td>12813.01</td>\n",
       "      <td>12000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>344407855</td>\n",
       "      <td>Hidden Love Letters</td>\n",
       "      <td>Video Games</td>\n",
       "      <td>Games</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2017-11-10</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2017-10-10 10:03:54</td>\n",
       "      <td>723.00</td>\n",
       "      <td>106</td>\n",
       "      <td>FR</td>\n",
       "      <td>44.60</td>\n",
       "      <td>842.59</td>\n",
       "      <td>582.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2037941839</td>\n",
       "      <td>Do You Have An Outdoor Grill? Use It To Roast ...</td>\n",
       "      <td>Food</td>\n",
       "      <td>Food</td>\n",
       "      <td>USD</td>\n",
       "      <td>2016-05-10</td>\n",
       "      <td>199000.0</td>\n",
       "      <td>2016-04-10 02:44:49</td>\n",
       "      <td>104.00</td>\n",
       "      <td>6</td>\n",
       "      <td>US</td>\n",
       "      <td>104.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>199000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               name     category  \\\n",
       "0  1426698687  RAPPY: The 3D printer with position feedback c...  3D Printing   \n",
       "1  1633937505            Unborn in America - A New Cabaret Opera      Musical   \n",
       "2   815178419     The Chronicles of Count Carlos: Son of Dracula  Comic Books   \n",
       "3   344407855                                Hidden Love Letters  Video Games   \n",
       "4  2037941839  Do You Have An Outdoor Grill? Use It To Roast ...         Food   \n",
       "\n",
       "  main_category currency    deadline      goal             launched   pledged  \\\n",
       "0    Technology      USD  2014-02-16  100000.0  2014-01-16 04:48:30  21543.00   \n",
       "1       Theater      GBP  2014-12-03    2500.0  2014-11-06 23:41:21   2600.00   \n",
       "2        Comics      USD  2016-09-01   12000.0  2016-07-03 19:39:13  12813.01   \n",
       "3         Games      EUR  2017-11-10     500.0  2017-10-10 10:03:54    723.00   \n",
       "4          Food      USD  2016-05-10  199000.0  2016-04-10 02:44:49    104.00   \n",
       "\n",
       "   backers country  usd pledged  usd_pledged_real  usd_goal_real  \n",
       "0       49      US     21543.00          21543.00      100000.00  \n",
       "1       74      GB      4162.44           4078.30        3921.45  \n",
       "2      193      US       629.00          12813.01       12000.00  \n",
       "3      106      FR        44.60            842.59         582.70  \n",
       "4        6      US       104.00            104.00      199000.00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248596, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248596, 35)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248596,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['launched_datetime'] = pd.to_datetime(X_train['launched'])\n",
    "X_train['deadline_datetime'] = pd.to_datetime(X_train['deadline'])\n",
    "X_train['project_times'] = pd.to_datetime(X_train['deadline']) - pd.to_datetime(X_train['launched'])\n",
    "'''This extracts the project days from the total project time'''\n",
    "X_train['project_length'] = X_train.project_times.dt.days\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop([\"category\", \"launched_datetime\",'deadline_datetime',\"main_category\", \"country\", \"name\",\n",
    "                       \"currency\", \"launched\", 'project_times',\"backers\", \"pledged\", \"usd_pledged_real\",\n",
    "                       \"usd pledged\", \"deadline\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = pd.concat(objs=[X_train, ohe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape, X_train2.shape, ohe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=30, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=2019, splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=2019,\n",
    "                             min_samples_leaf=30,\n",
    "                             criterion=\"gini\",\n",
    "                             min_samples_split=2)\n",
    "\n",
    "clf.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Create DOT data\n",
    "# dot_data = tree.export_graphviz(clf, \n",
    "#                                 out_file=None, \n",
    "#                                 feature_names=X_train.columns,  \n",
    "#                                 class_names=[\"failed\", \"successful\"])\n",
    "\n",
    "# # Draw graph\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "\n",
    "# # Show graph\n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well did our model do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto', drop='first',\n",
       "              dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "              n_values=None, sparse=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder(drop='first', categories=\"auto\")\n",
    "encoder.fit(X_test[[\"category\", \"main_category\", \"country\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_Academic</th>\n",
       "      <th>category_Accessories</th>\n",
       "      <th>category_Action</th>\n",
       "      <th>category_Animals</th>\n",
       "      <th>category_Animation</th>\n",
       "      <th>category_Anthologies</th>\n",
       "      <th>category_Apparel</th>\n",
       "      <th>category_Apps</th>\n",
       "      <th>category_Architecture</th>\n",
       "      <th>category_Art</th>\n",
       "      <th>...</th>\n",
       "      <th>country_IT</th>\n",
       "      <th>country_JP</th>\n",
       "      <th>country_LU</th>\n",
       "      <th>country_MX</th>\n",
       "      <th>country_NL</th>\n",
       "      <th>country_NO</th>\n",
       "      <th>country_NZ</th>\n",
       "      <th>country_SE</th>\n",
       "      <th>country_SG</th>\n",
       "      <th>country_US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_Academic  category_Accessories  category_Action  category_Animals  \\\n",
       "0                0.0                   0.0              0.0               0.0   \n",
       "1                0.0                   0.0              0.0               0.0   \n",
       "2                0.0                   0.0              0.0               0.0   \n",
       "3                0.0                   0.0              0.0               0.0   \n",
       "4                0.0                   0.0              0.0               0.0   \n",
       "\n",
       "   category_Animation  category_Anthologies  category_Apparel  category_Apps  \\\n",
       "0                 0.0                   0.0               0.0            0.0   \n",
       "1                 0.0                   0.0               0.0            0.0   \n",
       "2                 0.0                   0.0               0.0            1.0   \n",
       "3                 0.0                   0.0               0.0            0.0   \n",
       "4                 0.0                   0.0               0.0            0.0   \n",
       "\n",
       "   category_Architecture  category_Art     ...      country_IT  country_JP  \\\n",
       "0                    0.0           0.0     ...             0.0         0.0   \n",
       "1                    0.0           0.0     ...             0.0         0.0   \n",
       "2                    0.0           0.0     ...             0.0         0.0   \n",
       "3                    0.0           0.0     ...             0.0         0.0   \n",
       "4                    0.0           0.0     ...             0.0         0.0   \n",
       "\n",
       "   country_LU  country_MX  country_NL  country_NO  country_NZ  country_SE  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   country_SG  country_US  \n",
       "0         0.0         1.0  \n",
       "1         0.0         1.0  \n",
       "2         0.0         1.0  \n",
       "3         0.0         1.0  \n",
       "4         0.0         1.0  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = pd.DataFrame(encoder.transform(X_test[[\"category\", \"main_category\", \"country\"]]).toarray(),\n",
    "                   columns=encoder.get_feature_names([\"category\", \"main_category\", \"country\"]))\n",
    "ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['launched_datetime'] = pd.to_datetime(X_test['launched'])\n",
    "X_test['deadline_datetime'] = pd.to_datetime(X_test['deadline'])\n",
    "X_test['project_times'] = pd.to_datetime(X_test['deadline']) - pd.to_datetime(X_test['launched'])\n",
    "'''This extracts the project days from the total project time'''\n",
    "X_test['project_length'] = X_test.project_times.dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop([\"category\", \"launched_datetime\",'deadline_datetime',\"main_category\", \"country\", \"name\",\n",
    "                       \"currency\", \"launched\", 'project_times',\"backers\", \"pledged\", \"usd_pledged_real\",\n",
    "                       \"usd pledged\", \"deadline\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = pd.concat(objs=[X_test, ohe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=30, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=2019, splitter='best')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=2019,\n",
    "                             min_samples_leaf=30,\n",
    "                             criterion=\"gini\",\n",
    "                             min_samples_split=2)\n",
    "\n",
    "clf.fit(X_test2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create DOT data\n",
    "# dot_data = tree.export_graphviz(clf, \n",
    "#                                 out_file=None, \n",
    "#                                 feature_names=X_train.columns,  \n",
    "#                                 class_names=[\"failed\", \"successful\"])\n",
    "\n",
    "# # Draw graph\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "\n",
    "# # Show graph\n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.replace('successful', 1)\n",
    "y_train = y_train.replace('failed', 0)\n",
    "\n",
    "y_test = y_test.replace('successful', 1)\n",
    "y_test = y_test.replace('failed', 0)\n",
    "\n",
    "y_pred = y_pred.replace('successful', 1)\n",
    "y_pred = y_pred.replace('failed', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :71.1546351941689\n",
      "\n",
      "AUC is :0.69\n",
      "\n",
      "Confusion Matrix\n",
      "----------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7127</td>\n",
       "      <td>3597</td>\n",
       "      <td>10724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4981</td>\n",
       "      <td>2463</td>\n",
       "      <td>7444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>12108</td>\n",
       "      <td>6060</td>\n",
       "      <td>18168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0     1    All\n",
       "True                         \n",
       "0           7127  3597  10724\n",
       "1           4981  2463   7444\n",
       "All        12108  6060  18168"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "# Calculate Accuracy \n",
    "acc = accuracy_score(y_test,y_pred) * 100\n",
    "print(\"Accuracy is :{0}\".format(acc))\n",
    "\n",
    "# Check the AUC for predictions\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"\\nAUC is :{0}\".format(round(roc_auc,2)))\n",
    "\n",
    "# Create and print a confusion matrix \n",
    "print('\\nConfusion Matrix')\n",
    "print('----------------')\n",
    "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Model 1\n",
    "\n",
    "Now we will prune our decision tree\n",
    "\n",
    "We can prune our trees using the following parameters:\n",
    "\n",
    "Maximum Depth\n",
    "Reduce the depth of the tree to build a generalized tree. \n",
    "\n",
    "Minimum Samples Leaf with Split\n",
    "Restrict the size of sample leaf\n",
    "\n",
    "Minimum Leaf Sample Size\n",
    "Size in terminal nodes can be fixed to 30, 100, 300 or 5% of total\n",
    "\n",
    "Maximum Leaf Nodes\n",
    "Reduce the number of leaf nodes\n",
    "\n",
    "Maximum Features\n",
    "Maximum number of features to consider when splitting a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the optimal tree depth for given data\n",
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_depth in max_depths:\n",
    "   dt = DecisionTreeClassifier(criterion='entropy', max_depth=max_depth)\n",
    "   dt.fit(X_train2, y_train)\n",
    "   train_pred = dt.predict(X_train2)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   # Add auc score to previous train results\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = dt.predict(X_test2)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   # Add auc score to previous test results\n",
    "   test_results.append(roc_auc)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(max_depths, train_results, 'b', label='Train AUC')\n",
    "plt.plot(max_depths, test_results, 'r', label='Test AUC')\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the optimal min-samples-split for given data\n",
    "min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_split in min_samples_splits:\n",
    "   dt = DecisionTreeClassifier(criterion='entropy', min_samples_split=min_samples_split)\n",
    "   dt.fit(X_train2, y_train)\n",
    "   train_pred = dt.predict(X_train2)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = dt.predict(X_test2)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(min_samples_splits, train_results, 'b', label='Train AUC')\n",
    "plt.plot(min_samples_splits, test_results, 'r', label='Test AUC')\n",
    "plt.xlabel('Min. Sample splits')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the optimal value for minimum sample leafs\n",
    "\n",
    "min_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_leaf in min_samples_leafs:\n",
    "   dt = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=min_samples_leaf)\n",
    "   dt.fit(X_train2, y_train)\n",
    "   train_pred = dt.predict(X_train2)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = dt.predict(X_test2)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(12,6))    \n",
    "plt.plot(min_samples_leafs, train_results, 'b', label='Train AUC')\n",
    "plt.plot(min_samples_leafs, test_results, 'r', label='Test AUC')\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Min. Sample Leafs')\n",
    "plt.legend()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best value for optimal maximum feature size\n",
    "max_features = list(range(1,X_train2.shape[1]))\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_feature in max_features:\n",
    "   dt = DecisionTreeClassifier(criterion='entropy', max_features=max_feature)\n",
    "   dt.fit(X_train2, y_train)\n",
    "   train_pred = dt.predict(X_train2)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = dt.predict(X_test2)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(max_features, train_results, 'b', label='Train AUC')\n",
    "plt.plot(max_features, test_results, 'r', label='Test AUC')\n",
    "\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('max features')\n",
    "plt.legend()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a classifier with optimal values identified above\n",
    "dt = DecisionTreeClassifier(criterion='entropy',\n",
    "                           max_features=4,\n",
    "                           max_depth=7,\n",
    "                           min_samples_split=0.8,\n",
    "                           min_samples_leaf=0.4)\n",
    "dt.fit(X_train2, y_train)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a regular decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(criterion = \"gini\", max_depth = 5) \n",
    "tree_clf.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.698136\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "#do something\n",
    "tree_clf = DecisionTreeClassifier(criterion = \"gini\", max_depth = 5) \n",
    "tree_clf.fit(X_train2, y_train)\n",
    "print(datetime.now() - startTime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "pred = tree_clf.predict(X_test2)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Accuracy for Decision Tree Classifier: {:.4}%\".format(accuracy_score(y_test, y_pred) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a bagged tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:12.602024\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "#do something\n",
    "bagged_tree =  BaggingClassifier(DecisionTreeClassifier(criterion='gini', max_depth=7), n_estimators=20)\n",
    "bagged_tree.fit(X_train2, y_train)\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_tree =  BaggingClassifier(DecisionTreeClassifier(criterion='gini', max_depth=7), n_estimators=20)\n",
    "bagged_tree.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_tree.score(X_train2, y_train)\n",
    "bagged_tree.score(X_test2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:09.449648\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "#do something\n",
    "forest = RandomForestClassifier(n_estimators=100, max_depth= 5)\n",
    "forest.fit(X_train2, y_train)\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, max_depth= 5)\n",
    "forest.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.score(X_train2, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_clf = AdaBoostClassifier()\n",
    "gbt_clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:09.518276\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "#do something\n",
    "adaboost_clf.fit(X_train2, y_train)\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:33.525982\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "#do something\n",
    "gbt_clf.fit(X_train2, y_train)\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_clf.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_clf.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_train_preds = adaboost_clf.predict(X_train2)\n",
    "adaboost_test_preds = adaboost_clf.predict(X_test2)\n",
    "gbt_clf_train_preds = gbt_clf.predict(X_train2)\n",
    "gbt_clf_test_preds = gbt_clf.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_acc_and_f1_score(true, preds, model_name):\n",
    "    acc = accuracy_score(true, preds)\n",
    "    f1 = f1_score(true, preds)\n",
    "    print(\"Model: {}\".format(model_name))\n",
    "    print(\"Accuracy: {}\".format(acc))\n",
    "    print(\"F1-Score: {}\".format(f1))\n",
    "    \n",
    "print(\"Training Metrics\")\n",
    "display_acc_and_f1_score(y_train, adaboost_train_preds, model_name='AdaBoost')\n",
    "print(\"\")\n",
    "display_acc_and_f1_score(y_train, gbt_clf_train_preds, model_name='Gradient Boosted Trees')\n",
    "print(\"\")\n",
    "print(\"Testing Metrics\")\n",
    "display_acc_and_f1_score(y_test, adaboost_test_preds, model_name='AdaBoost')\n",
    "print(\"\")\n",
    "display_acc_and_f1_score(y_test, gbt_clf_test_preds, model_name='Gradient Boosted Trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_confusion_matrix = confusion_matrix(y_test, adaboost_test_preds)\n",
    "adaboost_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_confusion_matrix = confusion_matrix(y_test, gbt_clf_test_preds)\n",
    "gbt_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_classification_report = classification_report(y_test, adaboost_test_preds)\n",
    "print(adaboost_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_classification_report = classification_report(y_test, gbt_clf_test_preds)\n",
    "print(gbt_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at scores, which one matters most? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a rule of thumb, if the cost of having False negative is high, we want to increase the model sensitivity and recall!\n",
    "\n",
    "On the other hand, if the cost of having False positive is high, then we want to increase the model specificity and precision! \n",
    "\n",
    "In our case, a false negative is -- the project would do well on kickstarter but we classified it as failing -- and a false positive is -- the project would fail on kickstarter but we classified it as successful.\n",
    "\n",
    "The cost of our False positive is higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import calinski_harabaz_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "scaled_data = ss.fit_transform(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df=pd.DataFrame(data=scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(scaled_df)\n",
    "pca_df = pd.DataFrame(data=pca_data, columns=['pca1', 'pca2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=3, random_state=10).fit(pca_df) # Must set number of clusters at initialization time!\n",
    "model_label = model.labels_\n",
    "model_centers= model.cluster_centers_\n",
    "\n",
    "# cluster predictions for each point are also stored in k_means.labels_ attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "scatter = ax.scatter(pca_df['pca1'], pca_df['pca2'],\n",
    "                    c=model_label, s=50)\n",
    "ax.set_title('K-Means Clustering')\n",
    "ax.set_xlabel('pca1')\n",
    "ax.set_ylabel('pca2')\n",
    "plt.colorbar(scatter)\n",
    "plt.scatter(model_centers[:,0], model_centers[:,1], c='red', marker='*');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
